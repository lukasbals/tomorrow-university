{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620316dc",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "We are now evaluating our best models. Our best models from the model optimization phase are K-Means and Hierarchical Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a3a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    v_measure_score,\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/X_umap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca4412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE CLUSTER EVALUATION\n",
      "=================================\n",
      "Clusters found: 4\n",
      "Noise points: 0\n",
      "Total samples: 185\n",
      "\n",
      "INTERNAL METRICS:\n",
      "----------------\n",
      "Silhouette Score: 0.563 (higher = better)\n",
      "Davies-Bouldin Index: 0.650 (lower = better)\n",
      "Calinski-Harabasz Index: 748.0 (higher = better)\n",
      "Overall quality assessment: Good\n",
      "\n",
      "STABILITY EVALUATION (20 trials)\n",
      "==============================\n",
      "Mean stability (ARI): 0.914 ± 0.060\n",
      "Stability assessment: ✅ Highly stable\n",
      "COMPREHENSIVE CLUSTER EVALUATION\n",
      "=================================\n",
      "Clusters found: 4\n",
      "Noise points: 0\n",
      "Total samples: 185\n",
      "\n",
      "INTERNAL METRICS:\n",
      "----------------\n",
      "Silhouette Score: 0.565 (higher = better)\n",
      "Davies-Bouldin Index: 0.676 (lower = better)\n",
      "Calinski-Harabasz Index: 724.0 (higher = better)\n",
      "Overall quality assessment: Good\n",
      "\n",
      "STABILITY EVALUATION (20 trials)\n",
      "==============================\n",
      "Mean stability (ARI): 0.809 ± 0.095\n",
      "Stability assessment: ✅ Highly stable\n"
     ]
    }
   ],
   "source": [
    "def comprehensive_cluster_evaluation(data, labels, external_labels=None):\n",
    "    \"\"\"Comprehensive evaluation using multiple metrics\"\"\"\n",
    "\n",
    "    print(\"COMPREHENSIVE CLUSTER EVALUATION\")\n",
    "    print(\"=\" * 33)\n",
    "\n",
    "    # Basic cluster information\n",
    "    unique_labels = np.unique(labels)\n",
    "    n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)\n",
    "    n_noise = np.sum(labels == -1) if -1 in unique_labels else 0\n",
    "\n",
    "    print(f\"Clusters found: {n_clusters}\")\n",
    "    print(f\"Noise points: {n_noise}\")\n",
    "    print(f\"Total samples: {len(labels)}\")\n",
    "\n",
    "    results = {\"n_clusters\": n_clusters, \"n_noise\": n_noise}\n",
    "\n",
    "    # Internal metrics (skip if insufficient clusters)\n",
    "    if n_clusters > 1:\n",
    "        print(f\"\\nINTERNAL METRICS:\")\n",
    "        print(\"-\" * 16)\n",
    "\n",
    "        # For DBSCAN, exclude noise points from evaluation\n",
    "        if -1 in unique_labels:\n",
    "            non_noise_mask = labels != -1\n",
    "            eval_data = data[non_noise_mask]\n",
    "            eval_labels = labels[non_noise_mask]\n",
    "        else:\n",
    "            eval_data = data\n",
    "            eval_labels = labels\n",
    "\n",
    "        # Calculate internal metrics\n",
    "        silhouette = silhouette_score(eval_data, eval_labels)\n",
    "        davies_bouldin = davies_bouldin_score(eval_data, eval_labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(eval_data, eval_labels)\n",
    "\n",
    "        print(f\"Silhouette Score: {silhouette:.3f} (higher = better)\")\n",
    "        print(f\"Davies-Bouldin Index: {davies_bouldin:.3f} (lower = better)\")\n",
    "        print(f\"Calinski-Harabasz Index: {calinski_harabasz:.1f} (higher = better)\")\n",
    "\n",
    "        results.update(\n",
    "            {\n",
    "                \"silhouette\": silhouette,\n",
    "                \"davies_bouldin\": davies_bouldin,\n",
    "                \"calinski_harabasz\": calinski_harabasz,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Interpret results\n",
    "        sil_quality = (\n",
    "            \"Excellent\"\n",
    "            if silhouette > 0.7\n",
    "            else \"Good\"\n",
    "            if silhouette > 0.5\n",
    "            else \"Fair\"\n",
    "            if silhouette > 0.25\n",
    "            else \"Poor\"\n",
    "        )\n",
    "        print(f\"Overall quality assessment: {sil_quality}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\n⚠️ Insufficient clusters for internal metrics\")\n",
    "        results.update(\n",
    "            {\"silhouette\": -1, \"davies_bouldin\": np.inf, \"calinski_harabasz\": 0}\n",
    "        )\n",
    "\n",
    "    # External metrics (if external labels provided)\n",
    "    if external_labels is not None and n_clusters > 1:\n",
    "        print(f\"\\nEXTERNAL METRICS:\")\n",
    "        print(\"-\" * 16)\n",
    "\n",
    "        ari = adjusted_rand_score(external_labels, labels)\n",
    "        nmi = normalized_mutual_info_score(external_labels, labels)\n",
    "        v_measure = v_measure_score(external_labels, labels)\n",
    "\n",
    "        print(f\"Adjusted Rand Index: {ari:.3f} (higher = better)\")\n",
    "        print(f\"Normalized Mutual Information: {nmi:.3f} (higher = better)\")\n",
    "        print(f\"V-Measure: {v_measure:.3f} (higher = better)\")\n",
    "\n",
    "        results.update({\"ari\": ari, \"nmi\": nmi, \"v_measure\": v_measure})\n",
    "\n",
    "        # Interpret external validation\n",
    "        ext_quality = \"Strong\" if ari > 0.7 else \"Moderate\" if ari > 0.4 else \"Weak\"\n",
    "        print(f\"External validation: {ext_quality} agreement\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def stability_evaluation(data, clustering_func, n_trials=20):\n",
    "    \"\"\"Evaluate clustering stability via bootstrap\"\"\"\n",
    "\n",
    "    print(f\"\\nSTABILITY EVALUATION ({n_trials} trials)\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    stability_scores = []\n",
    "\n",
    "    # Generate reference clustering\n",
    "    reference_labels = clustering_func(data)\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        # Bootstrap sample\n",
    "        bootstrap_data = resample(data, random_state=trial)\n",
    "        bootstrap_labels = clustering_func(bootstrap_data)\n",
    "\n",
    "        # Calculate stability (simplified - assumes same data size)\n",
    "        if len(bootstrap_labels) == len(reference_labels):\n",
    "            # Find the indices of the bootstrap samples in the original data\n",
    "            bootstrap_indices = (\n",
    "                bootstrap_data.index\n",
    "                if hasattr(bootstrap_data, \"index\")\n",
    "                else np.arange(len(bootstrap_data))\n",
    "            )\n",
    "            # Align reference_labels to the bootstrap sample\n",
    "            aligned_reference_labels = reference_labels[bootstrap_indices]\n",
    "            stability = adjusted_rand_score(aligned_reference_labels, bootstrap_labels)\n",
    "            stability_scores.append(stability)\n",
    "\n",
    "    if stability_scores:\n",
    "        mean_stability = np.mean(stability_scores)\n",
    "        std_stability = np.std(stability_scores)\n",
    "\n",
    "        print(f\"Mean stability (ARI): {mean_stability:.3f} ± {std_stability:.3f}\")\n",
    "\n",
    "        if mean_stability > 0.8:\n",
    "            stability_assessment = \"✅ Highly stable\"\n",
    "        elif mean_stability > 0.6:\n",
    "            stability_assessment = \"⚡ Moderately stable\"\n",
    "        else:\n",
    "            stability_assessment = \"❌ Unstable\"\n",
    "\n",
    "        print(f\"Stability assessment: {stability_assessment}\")\n",
    "\n",
    "        return {\n",
    "            \"mean_stability\": mean_stability,\n",
    "            \"std_stability\": std_stability,\n",
    "            \"assessment\": stability_assessment,\n",
    "        }\n",
    "    else:\n",
    "        print(\"❌ Stability evaluation failed\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def kmean_clustering_func(data):\n",
    "    return KMeans(n_clusters=4, random_state=42).fit_predict(data)\n",
    "\n",
    "\n",
    "kmean_labels = kmean_clustering_func(df)\n",
    "\n",
    "def hierarchical_clustering_func(data):\n",
    "    return AgglomerativeClustering(linkage=\"average\", n_clusters=4).fit_predict(data)\n",
    "\n",
    "\n",
    "hierarchical_labels = hierarchical_clustering_func(df)\n",
    "\n",
    "\n",
    "kmean_eval_results = comprehensive_cluster_evaluation(df, kmean_labels)\n",
    "kmean_stability_results = stability_evaluation(df, kmean_clustering_func)\n",
    "\n",
    "hierarchical_eval_results = comprehensive_cluster_evaluation(\n",
    "    df, hierarchical_labels\n",
    ")\n",
    "hierarchical_stability_results = stability_evaluation(\n",
    "    df, hierarchical_clustering_func\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
